{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aliyyah-u/NLP_Medical_NER/blob/main/NLP_coursework.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IbzjCqsrupf0"
      },
      "outputs": [],
      "source": [
        "__author__ = \"Aliyyah U.\"\n",
        "__version__ = \"IN3045 City St George's, University of London, Spring 2025\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Dataset"
      ],
      "metadata": {
        "id": "xSfjsptclwBq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2uqXCa343FdI"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade huggingface_hub\n",
        "\n",
        "# Login to access dataset\n",
        "from huggingface_hub import login\n",
        "login()\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "df = pd.read_parquet(\"hf://datasets/parsa-mhmdi/Medical_NER/data/train-00000-of-00001.parquet\")\n",
        "\n",
        "train_indices, test_indices = train_test_split(df.index, test_size=0.2, random_state=42)\n",
        "\n",
        "train_data = df.loc[train_indices]\n",
        "test_data = df.loc[test_indices]\n",
        "\n",
        "# Preview samples from train and test\n",
        "print(\"Train sample:\")\n",
        "print(train_data.iloc[0])\n",
        "print(\"\\nTest sample:\")\n",
        "print(test_data.iloc[0])\n",
        "\n",
        "# Token and tag lists for training set\n",
        "train_tokens = train_data.tokens.tolist()\n",
        "train_ner_tags = train_data.ner_tags.tolist()\n",
        "\n",
        "# Preview\n",
        "print(\"\\nSample training tokens:\")\n",
        "print(train_tokens[0])\n",
        "print(\"\\nSample training tags:\")\n",
        "print(train_ner_tags[0])\n",
        "\n",
        "# Extract unique tags\n",
        "#train_unique_tags = set(tag for sublist in train_ner_tags for tag in sublist)\n",
        "#print(\"\\nUnique training NER tags:\")\n",
        "#print(sorted(train_unique_tags))\n",
        "\n",
        "# Check if dataset was loaded\n",
        "#df[:5]\n",
        "\n",
        "#tokens = df.tokens.tolist()\n",
        "#print (tokens[:1])\n",
        "\n",
        "#extracting unique list of ner_tags\n",
        "#ner_tags = df.ner_tags.tolist()\n",
        "#print (ner_tags[:1])\n",
        "\n",
        "#unique_tags = set(tag for sublist in ner_tags for tag in sublist)\n",
        "#print(sorted(unique_tags))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8_dRIA_ZlV1o"
      },
      "outputs": [],
      "source": [
        "import spacy"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMyvem26N7EqVYMtuj5YHUX",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}