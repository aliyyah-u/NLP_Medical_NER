{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aliyyah-u/NLP_Medical_NER/blob/main/NLP_CW.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing & baseline"
      ],
      "metadata": {
        "id": "ritsx2wVwME3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets\n",
        "!pip install -U datasets huggingface_hub\n",
        "\n",
        "from datasets import load_dataset\n",
        "from huggingface_hub import login\n",
        "import pandas as pd\n",
        "\n",
        "login()\n",
        "\n",
        "# Load the dataset\n",
        "dataset = load_dataset(\"parsa-mhmdi/Medical_NER\")\n",
        "print('\\nDATASET FEATURES:\\n', dataset)\n",
        "\n",
        "# Show a dataset sample\n",
        "print('\\nA DATASET SAMPLE:')\n",
        "print(dataset[\"train\"][0][\"tokens\"])    # Text is already tokenised\n",
        "print(dataset[\"train\"][0][\"ner_tags\"])  # NER tags (already in BIO format)\n",
        "\n",
        "# Split dataset for testing\n",
        "dataset = dataset['train'].train_test_split(test_size=0.1)\n",
        "print('\\nTHE SPLIT DATASET FEATURES:\\n', dataset)\n",
        "\n",
        "# Check column types\n",
        "ner_feature = dataset[\"train\"].features\n",
        "print('\\nDATA TYPES:\\n', ner_feature)\n",
        "\n",
        "# Convert dataset contents into lists for processing\n",
        "train_tokens = dataset[\"train\"][\"tokens\"]\n",
        "train_tags = dataset[\"train\"][\"ner_tags\"]\n",
        "\n",
        "# View samples\n",
        "print(\"\\nSAMPLE TRAINING TOKENS:\")\n",
        "print(train_tokens[0])\n",
        "print(\"\\nSAMPLE TRAINING TAGS:\")\n",
        "print(train_tags[0])\n",
        "\n",
        "# See all unique tag values\n",
        "train_unique_tags = set(tag for sublist in train_tags for tag in sublist)\n",
        "print(\"\\nALL UNIQUE NER TAGS IN TRAINING SET:\")\n",
        "print(sorted(train_unique_tags))\n",
        "\n",
        "# Function to generate baseline predicted tags\n",
        "def add_predicted_tags(tokens, tags):\n",
        "    return [['Other'] * len(token_list) for token_list in tags]\n",
        "\n",
        "# Remove 'pred_ner_tags' column if already exists\n",
        "if 'pred_ner_tags' in dataset[\"train\"].column_names:\n",
        "    dataset[\"train\"] = dataset[\"train\"].remove_columns(\"pred_ner_tags\")\n",
        "\n",
        "# Generate and add predicted NER tags\n",
        "predicted_train_tags = add_predicted_tags(train_tokens, train_tags)\n",
        "dataset[\"train\"] = dataset[\"train\"].add_column(\"pred_ner_tags\", predicted_train_tags)\n",
        "\n",
        "# Dataframe for organised display\n",
        "df = dataset[\"train\"].to_pandas()\n",
        "\n",
        "def match_tokens_labels(tokens, true_tags, pred_tags):\n",
        "    df_display = pd.DataFrame({\n",
        "        \"Token\": tokens,\n",
        "        \"True Tag\": true_tags,\n",
        "        \"Pred Tag\": pred_tags\n",
        "    })\n",
        "    print(\"\\nSAMPLE OF TOKENS WITH TRUE AND PREDICTED NER TAGS\\n\")\n",
        "    print(df_display.head(20))\n",
        "\n",
        "# Show first training example\n",
        "match_tokens_labels(df[\"tokens\"][0], df[\"ner_tags\"][0], df[\"pred_ner_tags\"][0])"
      ],
      "metadata": {
        "id": "L5B4ogGCuk3x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing"
      ],
      "metadata": {
        "id": "yDIbSUjVevs9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports & load dataset"
      ],
      "metadata": {
        "id": "dJVEclQ1bPhu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets\n",
        "!pip install -U huggingface_hub datasets\n",
        "\n",
        "from datasets import load_dataset\n",
        "from huggingface_hub import login\n",
        "!pip install -U huggingface_hub\n",
        "login()\n",
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "dataset = load_dataset(\"parsa-mhmdi/Medical_NER\")"
      ],
      "metadata": {
        "id": "vb7M2gCIbGUF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Explore Dataset"
      ],
      "metadata": {
        "id": "gO9Z54WpcKGA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('\\nDATASET FEATURES:' + '\\n', dataset)\n",
        "\n",
        "# See dataset sample\n",
        "print('\\nA DATASET SAMPLE:')\n",
        "print(dataset[\"train\"][0][\"tokens\"])  # Can see that dataset is already tokenized\n",
        "print(dataset[\"train\"][0][\"ner_tags\"])  # Can see that tags are already in BIO format"
      ],
      "metadata": {
        "id": "bqas1RxZbby1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Extract Test Set & convert dataset to suitable format"
      ],
      "metadata": {
        "id": "zTWcZalPcTni"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split dataset for testing\n",
        "dataset = dataset['train'].train_test_split(test_size=0.1)\n",
        "print('\\nTHE SPLIT DATASET FEATURES:' + '\\n', dataset)\n",
        "\n",
        "# See type\n",
        "ner_feature = dataset[\"train\"].features\n",
        "print('\\nDATA TYPES:' + '\\n', ner_feature)\n",
        "\n",
        "# Convert dataset contents into lists for further processing\n",
        "df = dataset[\"train\"].to_pandas()\n",
        "train_tokens = df[\"tokens\"].tolist()\n",
        "train_tags = df[\"ner_tags\"].tolist()\n",
        "\n",
        "# View samples\n",
        "print(\"\\nSAMPLE TRAINING TOKENS:\")\n",
        "print(train_tokens[0])\n",
        "print(\"\\nSAMPLE TRAINING TAGS:\")\n",
        "print(train_tags[0])"
      ],
      "metadata": {
        "id": "oKUA_Qa4cAfd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## See actual tag distribution"
      ],
      "metadata": {
        "id": "12HqHNyac0Bt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# See all unique tag names\n",
        "train_unique_tags = set(tag for sublist in train_tags for tag in sublist)\n",
        "print(\"\\nALL UNIQUE NER TAGS IN TRAINING SET:\")\n",
        "print(sorted(train_unique_tags))"
      ],
      "metadata": {
        "id": "Ol_S88qrcrnM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Baseline (Model 1) - all predicted tags as 'Other'"
      ],
      "metadata": {
        "id": "sz02ItYie4kk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Baseline model (all predicted tags as 'Other')"
      ],
      "metadata": {
        "id": "tLU7LQ_FdK-K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to add predicted tags (just assigns \"Other\" for baseline)\n",
        "def add_predicted_tags(tokens, tags):\n",
        "    predicted_tags = [['Other'] * len(token_list) for token_list in tags]\n",
        "    return predicted_tags\n",
        "\n",
        "# Check if 'pred_ner_tags' already exists and remove it\n",
        "if 'pred_ner_tags' in dataset[\"train\"].column_names:\n",
        "    dataset[\"train\"] = dataset[\"train\"].remove_columns(\"pred_ner_tags\")\n",
        "\n",
        "# Add predicted NER tags to the dataset\n",
        "predicted_train_tags = add_predicted_tags(train_tokens, train_tags)\n",
        "dataset[\"train\"] = dataset[\"train\"].add_column(\"pred_ner_tags\", predicted_train_tags)\n",
        "\n",
        "# Updated function to display tokens, true labels, and predicted labels in a table format\n",
        "def match_tokens_labels(tokens, true_tags, pred_tags):\n",
        "    df = pd.DataFrame({\n",
        "        \"Token\": tokens,\n",
        "        \"True Tag\": true_tags,\n",
        "        \"Pred Tag\": pred_tags\n",
        "    })\n",
        "    print(\"\\nSAMPLE OF TOKENS WITH TRUE AND PREDICTED NER TAGS\\n\")\n",
        "    print(df.head(20))\n",
        "\n",
        "# Match tokens, true NER tags, and predicted \"Other\" labels for the first sample\n",
        "match_tokens_labels(train_tokens[0], train_tags[0], predicted_train_tags[0])"
      ],
      "metadata": {
        "id": "8ZVCB0CKjzxg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def add_predicted_tags(tokens, tags):\n",
        "    predicted_tags = [['Other'] * len(token_list) for token_list in tags]\n",
        "    return predicted_tags\n",
        "\n",
        "# Add predicted NER tags to the dataset\n",
        "predicted_train_tags = add_predicted_tags(train_tokens, train_tags)\n",
        "# Now, add predicted_ner_tags to the original dataset\n",
        "dataset[\"train\"] = dataset[\"train\"].add_column(\"predicted_ner_tags\", predicted_train_tags)\n",
        "\n",
        "# Print a sample of tokens and their true and predicted NER tags\n",
        "def match_tokens_labels(tokens, true_labels, predicted_labels):\n",
        "    line1 = \"\"\n",
        "    line2 = \"\"\n",
        "    line3 = \"\"\n",
        "    # Iterate over tokens, true labels, and predicted labels together\n",
        "    for word, true_label, predicted_label in zip(tokens, true_labels, predicted_labels):\n",
        "        max_length = max(len(word), len(true_label), len(predicted_label))\n",
        "        line1 += word + \" \" * (max_length - len(word) + 1)\n",
        "        line2 += true_label + \" \" * (max_length - len(true_label) + 1)\n",
        "        line3 += predicted_label + \" \" * (max_length - len(predicted_label) + 1)\n",
        "    # Print the output with correct alignment\n",
        "    print('\\nSAMPLE OF TOKENS WITH TRUE AND PREDICTED NER TAGS' + '\\n', line1)\n",
        "    print(line2)\n",
        "    print(line3)\n",
        "\n",
        "# Match tokens, true NER tags, and predicted \"Other\" labels for the first sample\n",
        "match_tokens_labels(train_tokens[0], train_tags[0], predicted_train_tags[0])\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Flatten true and predicted tags\n",
        "flat_true = [tag for sent in train_tags for tag in sent]\n",
        "flat_pred = [tag for sent in predicted_train_tags for tag in sent]\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(flat_true, flat_pred)\n",
        "print(f\"\\nBaseline Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Compute report excluding \"Other\"\n",
        "labels = sorted(set(flat_true) - {\"Other\"})\n",
        "report = classification_report(flat_true, flat_pred, labels=labels, zero_division=0)\n",
        "print(\"\\nBaseline Classification Report (excluding 'Other'):\\n\")\n",
        "print(report)"
      ],
      "metadata": {
        "id": "qDMPDFgZdJQ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DistilBERT (Model 2)"
      ],
      "metadata": {
        "id": "OKQsD4Dg04u3"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xIzekZKa04R3"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN1YdcDQ7Zltbcakyh3FTYy",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}